<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Joseph Chen's Homepage</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <img src="resources/header.png" alt="Joseph Chen's Homepage" />
    </header>
    <section id="bio">
        <img src="resources/roma.jpeg" alt="Portrait of Joseph Chen" id="bio-photo" style="width: auto; height: 260px;">
        <div id="bio-text">
            <h2>Biography</h2>
            <p> Hi there! Guten Tag ! Êó©Êô® ! üëè I am a fourth-year Ph.D. student at 
              <a href="https://www.polyu.edu.hk" style="color:4169E1;">The Hong Kong Polytechnic University (PolyU)</a> 
              under the supervision of 
              <b><a href="https://scholar.google.com/citations?user=w2HXPUUAAAAJ" style="color:4169E1;">Prof. Dr. Changwen Chen</a> (Interim Dean of Faculty of Computer and Mathematical Sciences, Chair Professor of Visual Computing, IEEE Fellow) and 
                <a href="https://scholar.google.com/citations?user=cuJ3QG8AAAAJ&hl=en" style="color:4169E1;">Prof. Dr. Zhen Lei</a> (IEEE Fellow)</b>.
              Before that, I received a B.S. degree in Automation Engineering from the University of Electronic Science and Technology of China (UESTC), and obtained an M.S. degree in Computer Science from the 
              <a href="https://www.ucas.ac.cn" style="color:4169E1;">University of Chinese Academy of Sciences (UCAS)</a> 
              under the supervision of 
              <b><a href="https://scholar.google.com/citations?user=J1vMnRgAAAAJ&hl=en" style="color:4169E1;">Prof. Dr. Qingming Huang</a> (Professor at UCAS, IEEE Fellow)</b>
              and 
              <b><a href="https://qianqianxu010.github.io" style="color:4169E1;">Prof. Dr. Qianqian Xu</a> (Professor at ICT, CAS)</b>. 
            </p>
            <p>My Chinese name is Èô≥Á•ñËÄÄ. My research interests cover topics in computer vision and deep learning, such as Salient Object Detection (SOD), Scene Graph Generation (SGG), and Large Language Models (LLMs). I am happy to collaborate with talented researchers in computer science.
            </p>
            <div class="icon-links">
                <a href="https://github.com/JosephChenHub" class="icon-link" target="_blank" title="Visit my GitHub">
                    <img src="resources/github.png" alt="GitHub Logo">
                    GitHub 
                </a>
                <a href="https://github.com/orgs/gpt4vision/" class="icon-link" target="_blank" title="Visit my GitHub">
                    gpt4vision
                </a>
                <a href="mailto:zuyao.chen@connect.polyu.hk" class="icon-link" title="Send me an email">
                    <img src="resources/email.jpeg" alt="Email Logo">
                    Email
                </a>
                <a href="https://scholar.google.com/citations?user=kuQ_mrAAAAAJ&hl=en" class="icon-link" target="_blank" title="Visit my Google Scholar">
                    <img src="resources/scholar.jpeg" alt="Google Scholar Logo">
                    Google Scholar
                </a>
                <a href="resources/cv_zuyao_chen-june2025.pdf" class="icon-link" target="_blank" title="View my CV">
                    Curriculum vitae
                </a>
            </div>  
        </div>
    </section>
    <section id="news">
        <h2>üî• News</h2>
        <ul>
            <li><b style="color:black;">2025-02</b>: I joined <a href="https://cvg.ethz.ch">Computer Vision and Geometry Group</a> @ <a href="https://ethz.ch/en.html">ETH Z√ºrich</a> as an academic guest 
                to work with <b><a href="https://people.inf.ethz.ch/marc.pollefeys/" style="color:4169E1;">Prof. Dr. Marc Pollefeys</a> and 
                    <a href="https://francisengelmann.github.io">Dr. Francis Engelmann</a></b>. </li>
            <li><b style="color:black;">2024-12</b>: I received HK PolyU's <a href=https://www.polyu.edu.hk/gs/docdrive/attachment_programme/GS_RSAP.pdf>RSAP</a> and <a href=https://www.polyu.edu.hk/en/gs/current-students/polyu-phd-scholars-icrf/>ICRF</a> scholarships . </li>
            <li><b style="color:black;">2024-10</b>: One paper has been selected as <b style="color:#D71F3B">Best Paper Candidate</b> ü•á at <a href="https://eccv.ecva.net/Conferences/2024" style="color:#004c99">ECCV 2024</a> . </li>
            <li><b style="color:black;">2024-07</b>: One paper has been accepted as <b style="color:#D71F3b">Oral </b> at <a style="color:#004c99" href="https://eccv.ecva.net/Conferences/2024">ECCV 2024 </a>.</li>
        </ul>
    </section>
    <section id="publications">
        <h2>Publications</h2>
        <div class="publication">
            <div class="publication-content" style="margin-top: 20px;">
                <div class="publication-images">
                    <img src="resources/R1SGG.png" alt="Publication related to SceneBench"> 
                </div>
                <div class="publication-info"> 
                    <h3>Compile Scene Graphs with Reinforcement Learning</h3>
                    <p><b style="color:black;">Zuyao Chen</b>, Jinlin Wu, Zhen Lei, Marc Pollefeys, and Changwen Chen <br>
                      <em>arXiv (preprint)</em>, 2025. <br> 
                    </p>
                    <p>
                      <a href="https://www.arxiv.org/pdf/2504.13617" style="color:#191970;">Paper</a> /
                      <a href="https://github.com/gpt4vision/R1-SGG">Code </a>  
                    </p>
                </div>
            </div>
            <div class="publication-content" style="margin-top: 20px;">
                <div class="publication-images">
                    <img src="resources/SceneBench-main.png" alt="Publication related to SceneBench"> 
                </div>
                <div class="publication-info"> 
                    <h3>What Makes a Scene ? Scene Graph-based Evaluation and Feedback for Controllable Generation</h3>
                    <p><b style="color:black;">Zuyao Chen</b>, Jinlin Wu, Zhen Lei, and Changwen Chen <br>
                      <em>arXiv (preprint)</em>, 2024. <br> 
                    </p>
                    <p>
                      <a href="https://arxiv.org/pdf/2411.15435" style="color:#191970;">Paper</a> 
                    </p>
                </div>
            </div>
             <!-- 1st work -->
            <div class="publication-content" style="margin-top: 20px;">
                <div class="publication-images">
                    <img src="resources/GPT4SGG-main.png" alt="Publication related to GPT4SGG"> 
                </div>
                <div class="publication-info"> 
                    <h3>GPT4SGG: Synthesizing Scene Graphs from Holistic and Region-specific Narratives</h3>
                    <p><b style="color:black;">Zuyao Chen</b>, Jinlin Wu, Zhen Lei, Zhaoxiang Zhang, and Changwen Chen <br>
                      <em>arXiv (preprint)</em>, 2023. <br> 
                    </p>
                    <p>
                      <a href="https://arxiv.org/pdf/2312.04314.pdf" style="color:#191970;">Paper</a> / 
                      <a href="https://github.com/gpt4vision/gpt4sgg-source">Code </a> / 
                      <a href="https://gpt4vision.github.io/gpt4sgg/">Project Page (to be updated)</a>  
                    </p>
                </div>
            </div>
             <!-- 2nd work -->
            <div class="publication-content">
                <div class="publication-images">
                    <img src="resources/OvSGTR-main.png" alt="Publication related to OvSGTR"> 
                </div>              
                <div class="publication-info"> 
                  <h3>Expanding Scene Graph Boundaries: Fully Open-vocabulary Scene Graph Generation via Visual-Concept Alignment and Retention</h3>
                  <p><b style="color:black;">Zuyao Chen</b>, Jinlin Wu, Zhen Lei, Zhaoxiang Zhang, and Changwen Chen <br>
                     European Conference on Computer Vision (<b style="color:black;">ECCV</b>), 2024.<br> 
                    (<b style="color:#D71F3B">Best Paper Candiate (15/8585)</b>, <b style="color:#D71F3B">oral presentation</b>) 
                  </p>
                  <p>
                    <a href="https://arxiv.org/pdf/2311.10988.pdf" style="color:#191970;">Paper</a> / 
                    <a href="https://github.com/gpt4vision/OvSGTR/">Code</a> /  
                    <a href="https://www.youtube.com/watch?v=aJFa2fOjmeU">Youtube</a> / 
                    <a href="https://github.com/gpt4vision/OvSGTR/tree/master/paper/Poster_OvSGTR_ECCV24.pdf">Poster</a>
                  </p>
                </div>
            </div>
            <!-- 3rd work -->
            <div class="publication-content">
              <div class="publication-images">
                <!-- Add multiple images if needed -->
                <img src="resources/TIP_main.png" alt="Publication related to DPANet">
              </div>
              <div class="publication-info">
                <h3>DPANet: Depth potentiality-aware gated attention network for RGB-D salient object detection</h3>
                <p><b style="color:black;">Zuyao Chen*</b>, Runmin Cong*, Qianqian Xu, and Qingming Huang<br>
                IEEE Transactions on Image Processing (<b style="color:black">TIP</b>), vol. 30, pp. 7012-7024, 2021.<br>
                (* equal contribution) <b style="color:#D71F3B">ESI Highly Cited Paper</b></p>
                <!-- Links or other publication info can go here -->
                <p> 
                  <a href="https://arxiv.org/pdf/2003.08608.pdf" style="color:#191970;">Paper</a> / 
                  <a href="https://github.com/JosephChenHub/DPANet">Code</a> / 
                  <a href="https://rmcong.github.io/proj_DPANet.html">Project Page</a> /
                  <a href="https://www.bilibili.com/video/BV1Ry4y1m7WL/"> Talk (Chinese version)</a>
                </p>
              </div>
            </div>
            <div class="publication-content">
                <div class="publication-images">
                    <img src="resources/gcpa-vis.png" alt="Publication related to GCPANet"> 
                </div>
                <div class="publication-info">
                    <h3>Global context-aware progressive aggregation network for salient object detection</h3>
                    <p><b style="color:black;">Zuyao Chen</b>, Qianqian Xu, Runmin Cong,  and Qingming Huang<br>
                      Thirty-Fourth AAAI Conference on Artificial Intelligence (<b style="color:black";>AAAI</b>), pp. 10599-10606, 2020.<br>
                      (<b style="color:#D71F3B">oral presentation</b>) 
                    </p>
                    <p><a href="https://ojs.aaai.org/index.php/AAAI/article/download/6633/6487" style="color:#191970;">Paper</a> / 
                      <a href="https://github.com/JosephChenHub/GCPANet">Code</a> 
                    </p>
                </div>
            </div>
        </div> 
        <div class="publication-content">
            <div class="publication-images">
                <img src="resources/deep_partial_rank.png" alt="Publication related to deep partial rank">            
            </div>
            <div class="publication-info">
                <h3>Deep Partial Rank Aggregation for Personalized Attributes</h3>
                <p>Qianqian Xu, Zhiyong Yang, <b style="color:black;">Zuyao Chen</b>, Yangbangyan Jiang, Xiaochun Cao, Yuan Yao, Qingming Huang <br>
                  Thirty-Five AAAI Conference on Artificial Intelligence (<b style="color:black";>AAAI</b>), pp. 678-688, 2021.<br> 
                </p>
                <p>
                  <a href="https://ojs.aaai.org/index.php/AAAI/article/download/16148/15955" style="color:#191970;">Paper</a> 
                </p>
            </div>
        </div>
    </section>
    <section id="education">
        <h2>Education</h2>
        <ul>
            <li>Ph.D. student in Computer Science, Jan. 2022 -- present  The Hong Kong Polytechnic University (PolyU), Hong Kong SAR</li>
            <li>MSc. degree in Computer Science, 2017 -- 2020  University of Chinese Academy of Sciences (UCAS), Beijing, China</li>
            <li>BSc. degree in Automation Engineering, 2013 -- 2017 University of Electronic Science and Technology of China (UESTC), Cheng Du, China</li>
        </ul>
    </section>
    <section id="misc" style="margin-top:50px;">
        <h2>Miscellaneous</h2>
        <ul>
            <li>Â∏ùÁéãÊ∞£ËàáÂÜ†ËªçÁõ∏ -- Some Thoughts about Scientific Writing
                <a href="https://www.youtube.com/watch?v=wi2b7OHT848"> Youtube </a>
            </li>
            <li>Implement a JPEG Encoder from scratch (COMP5425 assignment2) 
                <a href="https://github.com/JosephChenHub/comp5425_assignment2_jpeg_encoder"> Code </a> / 
                <a href="https://www.youtube.com/watch?v=boDLS9jQ29I"> Youtube </a>
             </li>
        </ul>
        <div class="flex-container">
            <img src="resources/dsc7217.jpg" class="hk-image" alt="HK">  
            <p class="image-caption">Hong Kong@Joseph</p>
        </div>
        <p> My personal hobbies include photography, swimming, and hiking. </p>
    </section>
    <div class="flex-container" style="width:35%;height:auto;margin-top: 20px;margin-left:auto;margin-right:auto;">
        <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=EtSxtHoN54TmP9j87if6IgO-PE4TE8n7kLAXAWbdnpg&cl=ffffff&w=a"></script>
    </div>
    <footer>
        <p>Hong Kong @ Joseph</p>
        <p>Acknowledgement: ChatGPT for website building</p>
    </footer>
</body>
</html>
